/*
 mongo的优势就是性能读写好(尤其是查询最终直接是访问数据库的 大量写入更新的) 然后支持随意更改(随便加字段) 而且语法简洁 但是显然很多时候需要连表查询 不然相当于你要交互多次才行
pg的唯一的优势就是连表查询和统计优势以及 "传统操作钱的可靠性优势"

关于钱的操作与用户并发数这里的情况:

1. 第一种方案
直接用数据库 依赖行锁 比如说冻结余额是先读 余额够再扣 这个时候读的时候就要获取行锁
这种是pg/mysql基本的素质 传统银行几十年前的用法 如果数据大了就分库分表 久经验证没问题的

2.redis读数据库写方案
为了保持redis缓存和数据库的强一致性 需要有一个一致性锁来锁住 db/redis操作的过程
比如查询缓存没找到就读数据库然后更新redis 更新缓存就是操作数据库然后删除redis中值 整个过程用redis分布式锁来锁住
但是这种跟redis的交互次数会很多.还是以冻结为例 假设最后能冻结 就要经过一致性锁+查询redis缓存+更新redis/删除redis值 3个redis操作
这种适用于交易所多资产业务需要读的情况 但是没有改变写数据库的瓶颈

所以1/2种方案其实最后都是依赖于数据库 所以就是要那种事物处理能力要很大的 而且要有很强保证的数据库是一个基础设施的强需求.oceanbase/tidb这种就是代表
但是那个会花钱. 我们这种没钱咋整. 那只能异步批量合并更新写数据库了


3. 异步批量合并更新写数据库方案
撮合是内存撮合的这毫无疑问
问题是如何处理百万用户提交订单的资产冻结 如何处理百万用户撮合成交后的资产变化? 显然这不可能去实时冻结和解冻数据库资产的
把业务处理冻结程序搞成 用内存存储用户余额 然后这个处理程序是多副本选举的 这样不会单点故障 然后写wal日志推送到mq,撮合出来的订单也是写wal的
每个wal中的记录都是共享全局自增id的 这样方便消费者线程去严格顺序处理资产变化

首先需要接收rpc请求给予冻结解冻 其次需要一个mq消费程序用来接收充提交易等资产变化 同时更新内存
搞了全局自增id之后 启动的时候就是把wal日志给消费掉这样保证数据库中的资产是准确的 然后再启动这个资产服务把数据库的资产导入到内存中

如果挂了 也是走重启的路径.
关键是怎么挂 如果是自己挂了那没啥说的 如果是依赖组件挂了 比如接收mq/发送mq消息等出错了 你要么就手动搞补偿 要么就直接选择自主挂掉
这样能保证数据是完整不出错的 内存操作也能处理高并发 比如20w tps
但是容灾和服务可靠性没考虑 不过我现在考虑个毛容灾 不难 不过懒得弄 有团队一起弄再说

我们这个预测市场就算了所有资产相关操作我都想全部直接去操走数据库算了 有个1k tps就算不错了🤣🤣  这种数据库能hold住 搞个主写备读

*/