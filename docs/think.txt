/*

当前的一些问题
1 下单已经撮合推送消息出去的时候 日志要多打印些 如果万一出错了要能根据日志追踪到 不然排查问题很困难
2.写了redis_lock.rs 但是没使用. 实际当api多实例的时候就需要了 因为每个实例虽然有自己的限流但是多实例就可以多次下单了 虽然数据库做了事务性保障但是可以分布式锁处理下
3.消息在业务方面没有去重 但是实际在match_engine中写了helper.rs了
4.撮合那里也许还能优化 包括clone 可能更高效的算法等等

深度快照克隆优化
您问到有没有更好的方法避免克隆。我有两个建议：
方案A：使用Arc + 增量Diff（推荐）


方案A：使用增量哈希指纹对比（避免存储完整快照）

// 在 MatchEngine 中添加
pub struct MatchEngine {
	// ... existing fields ...

	// 替换完整快照为哈希指纹
	pub token_0_depth_fingerprint: FxHashMap<i32, (u64, u64)>, // price -> (bid_qty_hash, ask_qty_hash)
	pub token_1_depth_fingerprint: FxHashMap<i32, (u64, u64)>,
}

// 优化后的价格档位变化检测
pub fn update_price_level_changes_optimized(&mut self, current_depth: &OrderBookDepth) {
	let is_token_0 = current_depth.symbol.token_id == self.token_0_id;
	let (bid_changes, ask_changes, fingerprint) = if is_token_0 {
		(&mut self.token_0_bid_changes, &mut self.token_0_ask_changes, &mut self.token_0_depth_fingerprint)
	} else {
		(&mut self.token_1_bid_changes, &mut self.token_1_ask_changes, &mut self.token_1_depth_fingerprint)
	};

	// 直接对比当前价格档位与指纹
	for level in &current_depth.bids {
		match fingerprint.get(&level.price_i32) {
			Some(&(old_qty, _)) if old_qty != level.total_quantity_u64 => {
				bid_changes.insert(level.price_i32, level.total_quantity_u64);
			}
			None => {
				bid_changes.insert(level.price_i32, level.total_quantity_u64);
			}
			_ => {}
		}
		fingerprint.insert(level.price_i32, (level.total_quantity_u64, 0));
	}

	// 检测消失的价格档位
	fingerprint.retain(|&price, &(old_qty, _)| {
		if !current_depth.bids.iter().any(|l| l.price_i32 == price) && old_qty > 0 {
			bid_changes.insert(price, 0);
			false
		} else {
			true
		}
	});

	// asks 同理...
}
优势：
✅ 不存储完整快照，内存占用从 O(depth_levels * data_size) 降至 O(depth_levels * 16bytes)
✅ 对比速度更快（直接HashMap查找 vs Vec遍历）
7. 深度交叉插入优化
您说的对，必须克隆避免重复插入。但可以优化克隆的内容：
方案B：仅克隆PriceLevel元数据（而非整个Vec）
rust
// 优化前：完全克隆Vec
let original_token_0_bids = token_0_depth.bids.clone(); // 克隆整个Vec<PriceLevel>

// 优化后：仅提取需要的数据
fn cross_insert_depths_optimized(&self, token_0_depth: &mut OrderBookDepth, token_1_depth: &mut OrderBookDepth) {
	// 预先收集需要交叉插入的数据（仅存储元组，避免克隆PriceLevel结构体）
	let token_0_bid_data: Vec<(i32, u64, usize)> = token_0_depth.bids.iter()
		.map(|l| (l.price_i32, l.total_quantity_u64, l.order_count))
		.collect();

	let token_0_ask_data: Vec<(i32, u64, usize)> = token_0_depth.asks.iter()
		.map(|l| (l.price_i32, l.total_quantity_u64, l.order_count))
		.collect();

	// 同样收集 token_1 数据...

	// 现在可以安全地修改 token_1_depth，因为已经提取了 token_0 的数据
	for (price_i32, quantity, order_count) in token_0_bid_data {
		let new_price_i32 = 10000 - price_i32;
		self.insert_or_merge(&mut token_1_depth.asks, format_price(new_price_i32), new_price_i32, quantity, order_count);
	}

	// ... 其他交叉插入

	// 最后一次性排序
	token_0_depth.bids.sort_unstable_by(|a, b| b.price_i32.cmp(&a.price_i32));
	token_0_depth.asks.sort_unstable_by(|a, b| a.price_i32.cmp(&b.price_i32));
	token_1_depth.bids.sort_unstable_by(|a, b| b.price_i32.cmp(&a.price_i32));
	token_1_depth.asks.sort_unstable_by(|a, b| a.price_i32.cmp(&b.price_i32));
}
优势：
✅ 克隆开销从 sizeof(PriceLevel) * N 降至 (4+8+8) * N = 20N bytes
✅ 减少内存分配次数
✅ 使用 sort_unstable_by 更快（不保证稳定性但够用）
5. 交叉撮合算法优化
您提到预测市场的特殊性。我仔细看了 get_cross_matching_orders，确实有优化空间：
当前瓶颈：
rust
// engine.rs:473-479
let remaining_quantity = if let Some(order) = self.token_0_orders.get(&order_id) {
	order.remaining_quantity
} else if let Some(order) = self.token_1_orders.get(&order_id) {
	order.remaining_quantity
} else {
	continue;
};
问题：每次都查询两个HashMap
优化方案：预先标记订单所属的订单簿
rust
// 在 get_cross_matching_orders 中优化
fn get_cross_matching_orders(&self, taker: &Order) -> Vec<(String, i32)> {
	let mut candidates = Vec::new();
	match taker.side {
		OrderSide::Buy => {
			let same_result_orderbook = if taker.symbol.token_id == self.token_0_id {
				&self.token_0_orderbook
			} else {
				&self.token_1_orderbook
			};
			let opposite_result_orderbook = if taker.symbol.token_id == self.token_0_id {
				&self.token_1_orderbook
			} else {
				&self.token_0_orderbook
			};

			// 标记订单来源（0=token_0, 1=token_1）
			let same_orders_map = if taker.symbol.token_id == self.token_0_id {
				&self.token_0_orders
			} else {
				&self.token_1_orders
			};
			let opposite_orders_map = if taker.symbol.token_id == self.token_0_id {
				&self.token_1_orders
			} else {
				&self.token_0_orders
			};

			// 收集同结果卖单（带来源标记）
			for (price_key, orders) in same_result_orderbook.asks.iter() {
				if *price_key > taker.price { break; }
				for order in orders {
					if taker.price >= order.price {
						candidates.push((order.order_id.clone(), order.price, order.order_num, 0u8)); // 0=same
					}
				}
			}

			// 收集相反结果买单
			for (_, orders) in opposite_result_orderbook.bids.iter() {
				for order in orders {
					if taker.price >= order.opposite_result_price {
						candidates.push((order.order_id.clone(), order.opposite_result_price, order.order_num, 1u8)); // 1=opposite
					}
				}
			}

			// 排序
			candidates.sort_by(|a, b| {
				match a.1.cmp(&b.1) {
					std::cmp::Ordering::Equal => a.2.cmp(&b.2),
					other => other,
				}
			});

			// 优化累积逻辑：根据来源标记直接查询对应HashMap
			let mut result = Vec::new();
			let mut accumulated_quantity = 0u64;
			for (order_id, price, _, source) in candidates {
				let remaining_quantity = if source == 0 {
					same_orders_map.get(&order_id)?.remaining_quantity
				} else {
					opposite_orders_map.get(&order_id)?.remaining_quantity
				};

				accumulated_quantity += remaining_quantity;
				result.push((order_id, price));
				if accumulated_quantity >= taker.remaining_quantity {
					break;
				}
			}
			result
		}
		// Sell 同理...
	}
}
优势：
✅ 减少50% HashMap查询（从2次降至1次）
✅ 提前退出优化（累积量满足后立即break）


20251111
1. 我们暂时不设置标签
2. trending就是按照new/end/volume排序 如果要自定义trending_value值 显然这需要一个单独的分析程序定时去分析每个市场的trending_value值 然后我才好排序给到客户端
3. 暂时不提供临时添加选项 也就是说选项是和市场一起上的 市场开启了选项都有效 也不提供删除选项
4. 暂时不弄convert 就是多选项市场中单个选项的no不能转为其他选项的yes
5. 暂时不提供市场延迟开启 暂停等 以合约为准 合约方面负责市场的创建和结束
6. 暂时约定多市场的结果只能是yes或者no,没有选项不受这个约定(有且只有2个可能的结果) 市场仅结束之后 只统一结算一次.
 举例 一场电竞比赛或者球赛 不实时提供单场或者单节的预测 只提供整场比赛的输赢预测
 湖人vs火箭 约定不提供多个选项 结果可能是湖人或者火箭
 美国总统选举 有多个选项 比如特朗普/拜登/奥巴马 每个选项的结果只能是yes或者no


TODO_List:
多副本导致的顺序不一致 以及 消息不自己xdel 而是留住自动维护一个最大值 以及是否是从0开始$开始
目前api/websocket都是多副本 然后其他都是单副本模式
asset理论上也应该多副本 持仓变化来自于充值提现split merge redeem,但是是rpc没办法保持顺序 所以未来如果要顺序的话只能通过stream  不同的用户路由到不同的stream 单个stream中用户顺序一致就不会有持仓顺序问题了
但是我们当前还是asset还是单副本好了
*/
